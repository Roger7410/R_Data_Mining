mat<-matrix(rnorm(200000,50,7),10000,20)
rms<-rowMeans(mat)
par(mfrow=c(2,1))
hist(rnorm(10000,50,7),breaks=50,xlim=c(30,70),col="orange")
hist(rms,breaks=50,xlim=c(30,70),col="blue")
proc.time()-ptm
sd(samp20)
lln=vector()  #initialize vector to store coin flips
res<-vector() # initialize vector to keep track of empirical probability
n<-10000      # set number of flips
for (i in 1:n){
lln<-c(lln,sample(0:1,1))
res<-c(res,sum(lln)/length(lln))
}
plot(res)
mean(res[9001:10000]) # find mean of the last thousand flips
sd(res[9001:10000])   # find the standard deviation of the last thousand flips
means10<-rep(NA,10000)
means20<-rep(NA,10000)
means80<-rep(NA,10000)
for (i in 1:10000){
samp10<-rexp(10,rate=.25)
samp20<-rexp(20,rate=.25)
samp80<-rexp(80,rate=.25)
means10[i]<-mean(samp10)
means20[i]<-mean(samp20)
means80[i]<-mean(samp80)
}
par(mfrow=c(2,2))
hist(rexp(10000,rate=.25),breaks=50,xlim=c(0,8))
hist(means10,breaks=50,xlim=c(0,8))
hist(means20,breaks=50,xlim=c(0,8))
hist(means80,breaks=50,xlim=c(0,8))
n<-c(2,3,5)
s<-c("aa","bb","Cc")
b<-c(T,F,F)
df<-data.frame(n,s,b)
mtcars
head(mtcars)
help(mtcars)
x<-rnorm(100)
y<-rnorm(100)
z<-sample(c("A","B","C"),size=100,replace=T,prob=c(.4,.3,.3))
df<-data.frame(x,y,z)
df
head(df)
colnames(df)<-c("col1","col2","name")
df$col1
head(df$col1)
hist(df$col1)
df[1:6,]
df[1,3]
df[1:6,1:2]
df[1,3]
df[2,3]
summary(df)
df[df$name=="A",1:3]
df[df$col1<0,]
df[df$name=="A",]
df[df$col1<0,1:2]
df$col1<0 & df$col2>0
x<-data.frame(col1=5,col2=7,name="Dave")
head(df)
df
df<-rbind(df,x)
df
crazy<-rnorm(101,11,2)
df<-cbind(df,crazy)
df
library(MASS)
library(ISLR)
head(Boston)
Boston
fix(Boston)
names(Boston)
?Boston
medv
lm.fit=lm(medv~lstat,data=Boston)
attach(Boston)
lm.fit
summary(lm.fit)
lm.fit$coefficients
names(lm.fit)
coef(lm.fit)
lm.fit$qr
confint(lm.fit)
predict(lm.fit,data.frame(lstat=(c(5,10,15))),interval="confidence")
predict(lm.fit,data.frame(lstat=(c(5,10,15))),interval="prediction")
plot(lstat,medv)
abline(lm.fit)
abline(lm.fit,lwd=3,col="red")
plot(lstat,medv,col="red")
plot(lstat,medv,pch=20)
plot(lstat,medv,pch="+")
plot(1:20,1:20,pch=1:20)
par(mfrow=c(2,2))
plot(lm.fit)
plot(predict(lm.fit),residuals(lm.fit))
plot(predict(lm.fit),rstudent(lm.fit))
plot(hatvalues(lm.fit))
which.max(hatvalues(lm.fit))
library(car)
vif(lm.fit)
Load=function(){
library(ISLR)
library(MASS)
print("The libraries have been loaded")
}
Load()
plot(predict(lm.fit),residuals(lm.fit))
plot(predict(lm.fit),rstudent(lm.fit))
p <- c(6,5,4,3,2,1)
pp <- c(2,3)
p[pp]
p = p[-pp]
p = p[-pp]
p[p>3]
p[p>3] <- 7
p[p>3] <- c(8,9,10)
p <- c(6,5,4,3,2,1)
pp <- c(2,3)
p[pp]
p = p[-pp]
p[p>3]
p[p>3] <- 7
p[p>3] <- c(8,9,10)
p[]
seq(1,10,3)
seq(1,100,3)
seq(1,99,3)
1:40
seq(1,100,length=4)
seq(1,99,length=4)
as.integer(3.2)
as.character(3.2)
as.array(3.2)
1&2
0&1
1&&2
0|1
0||1
a <- list(name="Joe",4,foo=c(1,2,3))
a$name
a$foo
a$``
a[[2]]
a$aaa = TRUE
a[[6]] = "like"
a[[9]] -> oo = "b"
m <- array(c(1,2,3,4,5,6), dim=c(2,3), by.row = TRUE)
m by.row=TRUE
mat9 <- matrix(c(rep(1, 3), rep(2, 3)), 2, byrow = T)
f <- function(a, b)
{
return (a+b)
}
f(2,3)
x <- 1:3
typeof(x)
result<-c(0,0)
x<-sample(10,50,replace = TRUE)
for(i in 1:50){
if(x[i]<=6){
result[1]<-result[1]+1
}else{
result[2]<-result[2]+1
}
}
print(result[1])
print(result[2])
hist(x)
x <- c(1,2,3,4,5,6)
y <- x^2
print(y)
mean(y)
var(y)
lm_1 <- lm(y ~ x)
print(lm_1)
summary(lm_1)
par(mfrow=c(2,2))
plot(lm_1)
results<-vector(mode="integer",length=100000)
results<-vector(mode="integer",length=100000)
for(i in 1:100000){
heads<-0
x<-sample(10,50,replace = TRUE) # get 50 samples between 1-10
for(j in 1:50){
if(x[j]<=6){ #if the samples <=6, record as heads
heads<-heads+1
}
}
results[i]<-results[i]+heads
}
hist(results,breaks=50)
mean(results)
sd(results)
dnorm(35,29.99942,3.46195)
dnorm(35,30.01528,3.465176)#another test
#for calculate theoretical probability of 35 heads
sum<-1
a<-50
b<-15
b<-15
for(i in 1:15){
sum<-sum*a/b
a<-a-1
b<-b-1
}
sum<-sum*0.6^35*0.4^15
#35heads fewer
pnorm(35,29.99942,3.46195)
sum2<-0
for(i in 1:35){
tmp<-1
a<-50
b<-1
for(j in 1:i){
tmp<-tmp*a/b
a<-a-1
b<-b+1
}
tmp<-tmp*0.6^i*0.4^(50-i)
sum2<-sum2+tmp
}
pnorm(35,29.99942,3.46195)
sum2<-sum2+tmp
sum2<-sum2+tmp
sum2<-0
for(i in 1:35){
tmp<-1
a<-50
b<-1
for(j in 1:i){
tmp<-tmp*a/b
a<-a-1
b<-b+1
}
tmp<-tmp*0.6^i*0.4^(50-i)
sum2<-sum2+tmp
}
pnorm(35,29.99942,3.46195)
f.two<-function(x){
if(x==1) 0 #if only 1 person, 0
else{      #if more than 2, p = 1-all in different days
diff<-1
for(i in 1:x){
diff<-diff*(365-i+1)/365
}
1-diff
}
}
f.two(2)
f.two(10)
f.two(40)
#a plot for 1-365
results<-vector(mode="integer",length=365)
results[1]<-0
for(i in 2:365){
results[i]<-f.two(i)
}
plot(results)
means9<-rep(NA,10000)
for (i in 1:10000){
samp9<-rexp(9,rate=.1)
means9[i]<-mean(samp9)
}
mean(means9)#10.03646
sd(means9)  #3.355983
pnorm(7,10.03646,3.355983)#0.1827883
pnorm(7,10,10/3)#0.1840601
#hw2-3
means64<-rep(NA,10000)
for (i in 1:10000){
samp64<-rexp(64,rate=.1)
means64[i]<-mean(samp64)
}
mean(means64)#10.00554
sd(means64)  #1.258088
pnorm(7,10.00554,1.258088)#0.00844774
pnorm(7,10,10/8)#0.008197536
percentage<-sum(df$l.end<50 & df$r.end>50)/1000 #%95
means9<-rep(NA,1000)
for (i in 1:1000){
samp9<-rnorm(9,50,12)
means9[i]<-mean(samp9)
}
left9<-means9-1.96*12/3
right9<-means9+1.96*12/3
df<-data.frame(l.end=left9,r.end=right9)
head(df)
summary(df)
#hw2-4b
percentage<-sum(df$l.end<50 & df$r.end>50)/1000 #%95
percentage<-sum(df$l.end<50 & df$r.end>50)/1000 #%95
#hw2-5a
range<-seq(-4,4,.01)
range<-seq(-4,4,.01)
layout(matrix(1:6,ncol=3))
for(i in c(1,2,3,5,20,50)){
plot(range,dnorm(range),lty=1,col="orange")   #normal d
lines(range,dt(range,df=i),lty=2,col="blue")  #t
mtext(paste("df=",i),cex=1.2)                 #write text,cex-large the words
}
plot(dnorm(range))
plot(range,dnorm(range),lty=1,col="orange")   #normal d
lines(range,dt(range,df=i),lty=2,col="blue")  #t
mtext(paste("df=",i),cex=1.2)                 #write text,cex-large the words
for(i in c(1,2,3,5,20,50)){
plot(range,dnorm(range),lty=1,col="orange")   #normal d
lines(range,dt(range,df=i),lty=2,col="blue")  #t
mtext(paste("df=",i),cex=1.2)                 #write text,cex-large the words
}
plot(dnorm(range))
pnorm(-1)          #0.1586553
qnorm(0.025,0,1)   #-1.959964
pnorm(1.959964)
pt(-1,5)           #0.1816087
qt(0.025,5)        #-2.570582
pt(-1,10)          #0.1704466
qt(0.025,10)       #-2.228139
pt(-1,100)         #0.1598621
qt(0.025,100)      #-1.983972
#5c
samp<-rnorm(10,50,9)
#the mean will 95% in the interval
t.test(samp)$conf.int     #39.48664-55.44897
#5d
mean(samp)                #47.4678
47.47-1.96*9/sqrt(10)        #41.89
47.47+1.96*9/sqrt(10)        #50.29
#do100
samp100<-rnorm(100,50,9)
t.test(samp100)$conf.int  #47.73866-51.00789
mean(samp100)             #49.37328
49.37-1.96*9/sqrt(100)        #47.606
49.37+1.96*9/sqrt(100)        #51.134
#5e
t.test(samp,conf.level = .99)$conf.int
t.test(samp100,conf.level = .99)$conf.int
#hw2-7
#lets just use the normal distribution in the last question
#N(50,9)  mean=50, sd=9, var=81
#we will try to get sample variance in different sample size 10,100,1000,10000
for(n in c(10,100,1000,10000)){
samp<-rnorm(n,50,9)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
#the results of variances are
#10,    100,    1000,     10000
#100.12 83.87   82.22     80.78
#then we try it with exponent distribution
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rnorm(n,50,9)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
for(n in c(10,100,1000,10000)){
samp<-rexp(n,rate=.1)
s_samp<-sqrt(sum((samp-mean(samp))^2)/(n-1))#sqrt((Xi-x)^2/n-1)
print(s_samp^2)
}
tb<-scan("tb_react.data")
tb<-scan("tb_react.data")
tb<-scan("tb_react.data")
#1
tb<-scan("tb_react.data")
tb<-scan("tb_react.data")
qqnorm(tb)#linely
#hist(tb,breaks=20)
mean(tb)
s_tb<-sqrt(sum(tb^2)/(334-1))
t.test(tb,mu=0) #assume there are giving the same readings,
#p-value = 1.11e-13, so reject(different readings)
#2
samp10<-rnorm(10,50,7)
t.test(samp10,mu=50)
t.test(samp10,mu=51)
t.test(samp10,mu=49)
#3
df<-data.frame(l_end=numeric(0),r_end=numeric(0),t_stat=numeric(0),p_value=numeric(0),result=logical(0))
#head(df)
#x<-data.frame(l_end=1,r_end=7,t_stat=1,p_value=0.2,result=T)
#df<-rbind(df,x)
#head(df)
for(i in 1:1000){
samp10<-rnorm(10,50,7)
result<-t.test(samp10,mu=50,conf.level = .95)
#result
t.stat<-result[1]$statistic
p.val<-result[3]$p.value
l.end<-result[4]$conf.int[1]
r.end<-result[4]$conf.int[2]
rult<-F
if(p.val>0.05){
rult<-T
tb<-scan("tb_react.data")
tb<-scan("tb_react.data")
#stats lab2
#1
tb<-scan("tb_react.data")
qqnorm(tb)#linely
#hist(tb,breaks=20)
mean(tb)
s_tb<-sqrt(sum(tb^2)/(334-1))
t.test(tb,mu=0) #assume there are giving the same readings,
#p-value = 1.11e-13, so reject(different readings)
#2
samp10<-rnorm(10,50,7)
t.test(samp10,mu=50)
t.test(samp10,mu=51)
t.test(samp10,mu=49)
#3
df<-data.frame(l_end=numeric(0),r_end=numeric(0),t_stat=numeric(0),p_value=numeric(0),result=logical(0))
#head(df)
#x<-data.frame(l_end=1,r_end=7,t_stat=1,p_value=0.2,result=T)
#df<-rbind(df,x)
#head(df)
for(i in 1:1000){
samp10<-rnorm(10,50,7)
result<-t.test(samp10,mu=50,conf.level = .95)
#result
t.stat<-result[1]$statistic
p.val<-result[3]$p.value
l.end<-result[4]$conf.int[1]
r.end<-result[4]$conf.int[2]
rult<-F
if(p.val>0.05){
rult<-T
}
x<-data.frame(l_end=l.end,r_end=r.end,t_stat=t.stat,p_value=p.val,result=rult)
df<-rbind(df,x)
}
head(df)
sum(df$result==TRUE)
#3. again
veca<-rnorm(10000,11,3)
vecb<-rnorm(10000,3,4)
veca_b<-veca-vecb
hist(veca_b)
mean(veca_b)
sd(veca_b)
#4
vecaa<-rnorm(10000,10,3)
vecbb<-rnorm(10000,3,8)
vecca_b<-vecaa-vecbb
hist(vecca_b)
mean(vecca_b)
sd(vecca_b)
3*3+8*8
sqrt(73)
vecapb<-veca+vecb
hist(vecapb)
mean(vecapb)
sd(vecapb)
vecappb<-vecaa+vecbb
hist(vecappb)
mean(vecappb)
sd(vecappb)
#5
df<-read.csv("temperatures.csv")
men<-df$temp[df$gender=="Male"]
women<-df$temp[df$gender=="Female"]
t.test(men,women,mu=0)
#p-value= 0.02
tb<-scan("tb_react.data")
}
tb<-scan("tb_react.data")
qqnorm(tb)#linely
exists()
exit
exit()
